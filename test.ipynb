{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VCF_FILE = \"data/sample_vcfs/sample.vcf\"\n",
    "VCF_COLNAMES  = [\"chr\", \"pos\", \"id\", \"ref\", \"alt\"]\n",
    "\n",
    "\n",
    "G37_MIRNA_COORDS_FILE = \"data/mirna_coordinates/grch37_coordinates.csv\"\n",
    "G37_FASTAS_DIR = \"data/fasta/grch37\"\n",
    "\n",
    "INVALID_ROWS_FILE = \"invalid.txt\"\n",
    "\n",
    "MIRNA_COORDS_DIR = \"data/mirna_coordinates\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>id</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24255616</td>\n",
       "      <td>PD4120aC2_1_24255616_A_T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24255696</td>\n",
       "      <td>nazoa_1_24255696_C_T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24255696</td>\n",
       "      <td>nazooa_1_24255696_A_T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chr       pos                        id ref alt\n",
       "0   1  24255616  PD4120aC2_1_24255616_A_T   A   T\n",
       "1   1  24255696      nazoa_1_24255696_C_T   C   T\n",
       "2   1  24255696     nazooa_1_24255696_A_T   A   T"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def configure_pipeline_logging(log_file_path=None, log_level=logging.INFO):\n",
    "    \"\"\"Configure logging for the entire pipeline\n",
    "    \n",
    "    Args:\n",
    "        log_file_path (str, optional): Path to log file. If None, logs only to console\n",
    "        log_level (int, optional): Logging level. Defaults to logging.INFO\n",
    "    \"\"\"\n",
    "    # Create logger\n",
    "    logger = logging.getLogger('pipeline')\n",
    "    logger.setLevel(log_level)\n",
    "    \n",
    "    # Create formatters\n",
    "    console_formatter = logging.Formatter('%(asctime)s | %(levelname)8s | %(message)s')\n",
    "    file_formatter = logging.Formatter('%(asctime)s | %(levelname)8s | %(name)s | %(message)s')\n",
    "    \n",
    "    # Console handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "    console_handler.setLevel(logging.WARNING)  # Show only WARNING+ on console\n",
    "    \n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    # File handler if path provided\n",
    "    if log_file_path:\n",
    "        file_handler = logging.FileHandler(log_file_path)\n",
    "        file_handler.setFormatter(file_formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "    \n",
    "    # Prevent logging from propagating to the root logger\n",
    "    logger.propagate = False\n",
    "    \n",
    "    return logger\n",
    "\n",
    "logger = configure_pipeline_logging(\n",
    "    log_file_path='pipeline.log',\n",
    "    log_level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a few transformations inside pipeline will create secondary files. such as special cases or invalid rows. how do we handle them? these are the functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 19:33:43,376 |     INFO | validated=2 invalid=1\n"
     ]
    }
   ],
   "source": [
    "from scripts.pipeline_steps.step1 import *\n",
    "\n",
    "df = validate_ref_nucleotides(df, INVALID_ROWS_FILE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 19:34:23,736 |     INFO | mirna_mutations=1/2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>id</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>is_mirna</th>\n",
       "      <th>mirna_accession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24255616</td>\n",
       "      <td>PD4120aC2_1_24255616_A_T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>MIMAT0018932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24255696</td>\n",
       "      <td>nazooa_1_24255696_A_T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chr       pos                        id ref alt  is_mirna mirna_accession\n",
       "0   1  24255616  PD4120aC2_1_24255616_A_T   A   T         1    MIMAT0018932\n",
       "2   1  24255696     nazooa_1_24255696_A_T   A   T         0            None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_is_mirna_column(df, grch):\n",
    "    \"\"\"\n",
    "    Adds two columns to the input DataFrame:\n",
    "    'is_mirna': 1 if the mutation falls within a miRNA region, 0 otherwise\n",
    "    'mirna_accession': the accession number of the miRNA if 'is_mirna' is 1, None otherwise\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger('pipeline.mirna')\n",
    "    \n",
    "    # Load miRNA coordinates\n",
    "    mirna_coords_file = os.path.join(MIRNA_COORDS_DIR, f\"grch{grch}_coordinates.csv\")\n",
    "    coords = pd.read_csv(mirna_coords_file)\n",
    "    logger.debug(f\"Loaded {len(coords)} miRNA coordinates from GRCh{grch}\")\n",
    "\n",
    "    # Initialize new columns\n",
    "    df['is_mirna'] = 0\n",
    "    df['mirna_accession'] = None\n",
    "\n",
    "    # Convert datatypes for both dataframes\n",
    "    df['chr'] = df['chr'].astype(str)\n",
    "    df['pos'] = df['pos'].astype(int)\n",
    "    coords['chr'] = coords['chr'].astype(str)\n",
    "    coords['start'] = coords['start'].astype(int)\n",
    "    coords['end'] = coords['end'].astype(int)\n",
    "\n",
    "    # Match mutations to miRNAs\n",
    "    matched_count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        mutation_chr = row['chr']\n",
    "        mutation_start = row['pos']\n",
    "\n",
    "        matching_rnas = coords.loc[(coords['chr'] == mutation_chr) &\n",
    "                                 (coords['start'] <= mutation_start) &\n",
    "                                 (coords['end'] >= mutation_start)]\n",
    "\n",
    "        if not matching_rnas.empty:\n",
    "            df.at[index, 'is_mirna'] = 1\n",
    "            df.at[index, 'mirna_accession'] = matching_rnas['mirna_accession'].values[0]\n",
    "            matched_count += 1\n",
    "\n",
    "    logger.info(f\"mirna_mutations={matched_count} on miRNA/{len(df)} total\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "df = generate_is_mirna_column(df, 37)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1936653/1837632710.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = grouped.apply(apply_func)\n",
      "2025-01-22 19:35:17,390 |     INFO | sequences=2 positions=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>id</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>is_mirna</th>\n",
       "      <th>mirna_accession</th>\n",
       "      <th>upstream_seq</th>\n",
       "      <th>downstream_seq</th>\n",
       "      <th>wt_seq</th>\n",
       "      <th>mut_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24255616</td>\n",
       "      <td>PD4120aC2_1_24255616_A_T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>MIMAT0018932</td>\n",
       "      <td>CAGGCTGCTAAACAACAGAACGAGCACTGG</td>\n",
       "      <td>CTTGGAGCCAGAAGTCTTGGGCTCAAGCCC</td>\n",
       "      <td>CAGGCTGCTAAACAACAGAACGAGCACTGGACTTGGAGCCAGAAGT...</td>\n",
       "      <td>CAGGCTGCTAAACAACAGAACGAGCACTGGTCTTGGAGCCAGAAGT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24255696</td>\n",
       "      <td>nazooa_1_24255696_A_T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>CTGAATAATTCTGGGCAAATCAGTTGGACC</td>\n",
       "      <td>GTTACACCTCAGCCTTCTCATTTAGGAAAT</td>\n",
       "      <td>CTGAATAATTCTGGGCAAATCAGTTGGACCAGTTACACCTCAGCCT...</td>\n",
       "      <td>CTGAATAATTCTGGGCAAATCAGTTGGACCTGTTACACCTCAGCCT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chr       pos                        id ref alt  is_mirna mirna_accession  \\\n",
       "0   1  24255616  PD4120aC2_1_24255616_A_T   A   T         1    MIMAT0018932   \n",
       "1   1  24255696     nazooa_1_24255696_A_T   A   T         0            None   \n",
       "\n",
       "                     upstream_seq                  downstream_seq  \\\n",
       "0  CAGGCTGCTAAACAACAGAACGAGCACTGG  CTTGGAGCCAGAAGTCTTGGGCTCAAGCCC   \n",
       "1  CTGAATAATTCTGGGCAAATCAGTTGGACC  GTTACACCTCAGCCTTCTCATTTAGGAAAT   \n",
       "\n",
       "                                              wt_seq  \\\n",
       "0  CAGGCTGCTAAACAACAGAACGAGCACTGGACTTGGAGCCAGAAGT...   \n",
       "1  CTGAATAATTCTGGGCAAATCAGTTGGACCAGTTACACCTCAGCCT...   \n",
       "\n",
       "                                             mut_seq  \n",
       "0  CAGGCTGCTAAACAACAGAACGAGCACTGGTCTTGGAGCCAGAAGT...  \n",
       "1  CTGAATAATTCTGGGCAAATCAGTTGGACCTGTTACACCTCAGCCT...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_sequence_columns(df):\n",
    "    logger = logging.getLogger('pipeline.sequences')\n",
    "    \n",
    "    # Group by chromosome and position\n",
    "    grouped = df.groupby(['chr', 'pos'])\n",
    "    logger.debug(f\"Processing {len(grouped)} unique positions\")\n",
    "\n",
    "    def apply_func(group):\n",
    "        chr_val = group['chr'].iloc[0]\n",
    "        pos_val = group['pos'].iloc[0]\n",
    "        \n",
    "        group['upstream_seq'] = get_upstream_sequence(\n",
    "            chr_val, pos_val, NUCLEOTIDE_OFFSET)\n",
    "        group['downstream_seq'] = get_downstream_sequence(\n",
    "            chr_val, pos_val, group['ref'].iloc[0], NUCLEOTIDE_OFFSET)\n",
    "        group['wt_seq'] = group['upstream_seq'] + \\\n",
    "            group['ref'] + group['downstream_seq']\n",
    "        group['mut_seq'] = group['upstream_seq'] + \\\n",
    "            group['alt'] + group['downstream_seq']\n",
    "        return group\n",
    "\n",
    "    df = grouped.apply(apply_func)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    logger.info(f\"added sequences for rows={len(df)} positions={len(grouped)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "NUCLEOTIDE_OFFSET = 30\n",
    "\n",
    "df = add_sequence_columns(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_get_case_1_mutations(df, vcf_id, start, end, output_dir):\n",
    "    \"\"\"\n",
    "    Classifies mutations into case 1 and case 2, saves case 2 mutations to disk,\n",
    "    and returns the case 1 mutations.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger('pipeline.classifier')\n",
    "    \n",
    "    # Classify case 1 and case 2 mutations\n",
    "    case_1 = df[df.is_mirna == 0][[\"id\", \"wt_seq\", \"mut_seq\"]]\n",
    "    case_2 = df[df.is_mirna == 1][[\"id\", \"wt_seq\", \"mut_seq\"]]\n",
    "    \n",
    "    if not case_2.empty:\n",
    "        case_2_file = os.path.join(output_dir, f\"{vcf_id}_{start}_{end}_case_2.csv\")\n",
    "        case_2.to_csv(case_2_file, index=False)\n",
    "        logger.debug(f\"Saved case 2 mutations to {case_2_file}\")\n",
    "\n",
    "    logger.info(f\"classified mutations case1={len(case_1)} case2={len(case_2)}\")\n",
    "    return case_1\n",
    "\n",
    "\n",
    "classify_and_get_case_1_mutations(df, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline(VCF_FILE, 5, \"results/test\", \"vcffff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(vcf_full_path: str, chunksize: int, output_dir: str, vcf_id: str):\n",
    "    with ThreadPoolExecutor(max_workers=WORKERS) as executor:\n",
    "\n",
    "        futures = []\n",
    "        start_index = 0\n",
    "        for chunk in pd.read_csv(vcf_full_path, chunksize=chunksize, sep=\"\\t\", header=None, names=[\"chr\", \"pos\", \"id\", \"ref\", \"alt\"]):\n",
    "            end_index = start_index + len(chunk) - 1\n",
    "            future = executor.submit(\n",
    "                process_chunk, chunk, start_index, end_index, output_dir, vcf_id)\n",
    "            futures.append(future)\n",
    "            start_index = end_index + 1\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            start_index, end_index = future.result()\n",
    "            \n",
    "            \n",
    "\n",
    "def process_chunk(chunk: pd.DataFrame, start_index: int, end_index: int, output_dir: str, vcf_id: str) -> tuple:\n",
    "\n",
    "    result = analysis_pipeline(\n",
    "        chunk, start_index, end_index, output_dir, vcf_id)\n",
    "\n",
    "    # Write the result to a CSV file in the output directory\n",
    "    result_file = os.path.join(\n",
    "        output_dir, f'result_{start_index}_{end_index}.csv')\n",
    "    result.to_csv(result_file, index=False)\n",
    "\n",
    "    return start_index, end_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def analysis_pipeline(df: pd.DataFrame, start_index: int, end_index: int, output_dir: str, vcf_id: str, verbose: bool = False,) -> pd.DataFrame:\n",
    "\n",
    "    df = pd.read_csv(VCF_FILE, sep=\"\\t\", header=None, names=VCF_COLNAMES)\n",
    "    df[\"chr\"] = df[\"chr\"].astype(str)\n",
    "\n",
    "    df['id'] = df['id'].astype(str)\n",
    "    df['id'] += '_' + df['chr']+ '_' + df['pos'].astype(str) + '_' + df['ref'] + '_' + df['alt']\n",
    "\n",
    "    # rest of the logic\n",
    "    \n",
    "    return df "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirscribe-lean-IjTOmFCF-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
